{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b133ccf1-9253-45bf-8b5e-c8bcb83cf8af",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: sentence-transformers in /home/bmp166/.local/lib/python3.12/site-packages (3.3.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/bmp166/.local/lib/python3.12/site-packages (from sentence-transformers) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/lib/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /home/bmp166/.local/lib/python3.12/site-packages (from sentence-transformers) (2.5.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/lib/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: scipy in /usr/lib/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/bmp166/.local/lib/python3.12/site-packages (from sentence-transformers) (0.27.0)\n",
            "Requirement already satisfied: Pillow in /usr/lib/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (10.3.0)\n",
            "... (truncated) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fd34e023-eec7-42cb-a570-3e211f231584",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries are installed successfully!\n"
          ]
        }
      ],
      "source": [
        "import sentence_transformers\n",
        "import openai\n",
        "\n",
        "print(\"Libraries are installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "69ab0b8d-6bd9-40f2-a2cd-58ef575601cb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: sentence-transformers in /home/bmp166/.local/lib/python3.12/site-packages (3.3.1)\n",
            "Requirement already satisfied: pinecone-client in /home/bmp166/.local/lib/python3.12/site-packages (5.0.1)\n",
            "... (truncated) ...\n",
            "All chunks upserted to Pinecone successfully!\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers pinecone-client\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pinecone import Pinecone, ServerlessSpec, Index\n",
        "\n",
        "# setup\n",
        "YOUR_API_KEY = \"pcsk_r2pz5_UV2WuDc4A8KtaHcUPNca6fxptkvnFS14VU7rNCAB99kqmSDqAFSVdf4PwJgx5Mo\"  # <-- Replace with your actual Pinecone key\n",
        "INDEX_NAME   = \"chatbot-index\"\n",
        "\n",
        "# cleaned dir paths\n",
        "TXT_CLEANED_DIR = './files/processed_txt_files'\n",
        "M_CLEANED_DIR   = './files/processed_m_files'\n",
        "\n",
        "# Initialize sentence transformers model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Connect to Pinecone\n",
        "pc = Pinecone(api_key=YOUR_API_KEY)\n",
        "\n",
        "# Create the index if not already present\n",
        "if INDEX_NAME not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=INDEX_NAME,\n",
        "        dimension=384,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "        )\n",
        "    )\n",
        "    print(f\"Index '{INDEX_NAME}' created!\")\n",
        "else:\n",
        "    print(f\"Index '{INDEX_NAME}' already exists.\")\n",
        "\n",
        "desc = pc.describe_index(INDEX_NAME)\n",
        "host = desc.host\n",
        "index = Index(api_key=YOUR_API_KEY, host=host)\n",
        "\n",
        "# Helper function for Chunking\n",
        "def chunk_text(text, chunk_size=2000, overlap=200):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    text_length = len(text)\n",
        "    while start < text_length:\n",
        "        end = start + chunk_size\n",
        "        chunk = text[start:end]\n",
        "        chunks.append(chunk)\n",
        "        start += (chunk_size - overlap)\n",
        "    return chunks\n",
        "\n",
        "# Function to read files, chunk, embed, and upsert\n",
        "def upsert_folder(folder_path, file_extension, chunk_size=2000, overlap=200):\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith(file_extension):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "            text_chunks = chunk_text(content, chunk_size=chunk_size, overlap=overlap)\n",
        "            for i, chunk in enumerate(text_chunks):\n",
        "                chunk_id = f\"{file_name}_chunk_{i}\"\n",
        "                embedding = model.encode(chunk).tolist()\n",
        "                metadata = {\n",
        "                    \"text\": chunk,\n",
        "                    \"original_file\": file_name,\n",
        "                    \"chunk_index\": i\n",
        "                }\n",
        "                index.upsert([(chunk_id, embedding, metadata)])\n",
        "            print(f\"Upserted {len(text_chunks)} chunks for file: {file_name}\")\n",
        "\n",
        "# Upsert both directories\n",
        "upsert_folder(TXT_CLEANED_DIR, '.txt', chunk_size=2000, overlap=200)\n",
        "upsert_folder(M_CLEANED_DIR, '.m', chunk_size=2000, overlap=200)\n",
        "\n",
        "print(\"All chunks upserted to Pinecone successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "be4534e1-cfd5-4f22-849e-2b5d3e07f36f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ID: Dickinson, Lehman, Sane, 1999, Wing Rotation and the Aerodynamic Basis of Insect Flight, science.284.5422.1954.txt\n",
            "Score: 0.76667285\n",
            "No metadata available for this match.\n",
            "\n",
            "ID: Dickinson, Lehman, Sane, 1999, Wing Rotation and the Aerodynamic Basis of Insect Flight, science.284.5422.1954.txt_chunk_0\n",
            "Score: 0.76667285\n",
            "Chunk Text: research articles wing rotation and the aerodynamic basis of insect flight michael h dickinson1 fritzolaf lehmann2 sanjay p sane1 insects were the first animals to evolve active flight and remain unsu...\n",
            "\n",
            "ID: Dickinson, Lehman, Sane, 1999, Wing Rotation and the Aerodynamic Basis of Insect Flight, science.284.5422.1954.txt_chunk_22\n",
            "Score: 0.764329553\n",
            "Chunk Text: flapping wings suggest that the aerodynamics of insect flight may be explained by the interaction of three distinct yet interactive mechanisms delayed stall rotational circulation and wake capture whe...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query_embedding = model.encode(\"Explain how wing rotation works for insect flight\").tolist()\n",
        "results = index.query(vector=query_embedding, top_k=3, include_metadata=True)\n",
        "\n",
        "for match in results[\"matches\"]:\n",
        "    print(f\"ID: {match['id']}\")\n",
        "    print(f\"Score: {match['score']}\")\n",
        "    if \"metadata\" in match:\n",
        "        snippet = match[\"metadata\"].get(\"text\", \"\")\n",
        "        print(f\"Chunk Text: {snippet[:200]}...\\n\")\n",
        "    else:\n",
        "        print(\"No metadata available for this match.\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5a9cb40d-862b-484f-9643-5ae3aaedc14a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: openai in /home/bmp166/.local/lib/python3.12/site-packages (0.28.0)\n",
            "... (truncated) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2956c8bf-ecbf-4b85-98cc-c1cf55e428b1",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: openai==0.28.0 in /home/bmp166/.local/lib/python3.12/site-packages (0.28.0)\n",
            "... (truncated) ...\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install openai==0.28.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71d00a37-447e-4225-99f2-f69d8a43c939",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot ready! Type 'exit' or 'quit' to stop.\n",
            "\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "User:  \"Answer only based on the provided research data embeddings. If the information is not found, respond with: 'I don't know based on the research data provided.'\" What is the capital of france?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: I don't know based on the research data provided.\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "User:  capital of india\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: New Delhi\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "def chatbot():\n",
        "    print(\"Chatbot ready! Type 'exit' or 'quit' to stop.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"User: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        #Embed the user's question\n",
        "        query_embedding = model.encode(user_input).tolist()\n",
        "\n",
        "        #Query Pinecone for top chunks\n",
        "        results = index.query(\n",
        "            vector=query_embedding, \n",
        "            top_k=3, \n",
        "            include_metadata=True\n",
        "        )\n",
        "\n",
        "        # gather chunk text\n",
        "        retrieved_chunks = []\n",
        "        for match in results[\"matches\"]:\n",
        "            if \"metadata\" in match:\n",
        "                chunk_text = match[\"metadata\"].get(\"text\", \"\")\n",
        "                retrieved_chunks.append(chunk_text)\n",
        "\n",
        "        context_text = \"\\n\\n\".join(retrieved_chunks)\n",
        "\n",
        "        # build the prompt\n",
        "        prompt = f\"\"\"\n",
        "        You are an expert assistant. Use the following context to answer the user's question.\n",
        "        Context:\n",
        "        {context_text}\n",
        "\n",
        "        Question:\n",
        "        {user_input}\n",
        "\n",
        "        Provide a helpful, concise answer:\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[{\"role\": \"system\", \"content\": prompt}],\n",
        "                temperature=0.7,\n",
        "            )\n",
        "            answer = response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            answer = f\"Error calling OpenAI API: {e}\"\n",
        "\n",
        "        print(f\"Chatbot: {answer}\\n{'-'*60}\\n\")\n",
        "\n",
        "chatbot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "828329d1-97f0-47ca-bde5-011401770441",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "886ab78e-e4bc-4f61-9718-1516ccf00068",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('./files/embeddings.pkl', 'rb') as f:\n",
        "    embeddings = pickle.load(f)\n",
        "\n",
        "print(f\"Number of embeddings: {len(embeddings)}\")\n",
        "for file_name, embedding in list(embeddings.items())[:5]:\n",
        "    print(f\"File: {file_name}, Embedding Shape: {len(embedding)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c84f6731-04c7-4fe5-82ef-5b126dca307b",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install pinecone-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29e75109-69ee-48fe-a837-c8de11b1b819",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "pc = Pinecone(api_key=\"pcsk_r2pz5_UV2WuDc4A8KtaHcUPNca6fxptkvnFS14VU7rNCAB99kqmSDqAFSVdf4PwJgx5Mo\")\n",
        "\n",
        "index_name = \"chatbot-index\"\n",
        "\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=384,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "print(f\"Index {index_name} created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1d041cf-2003-4e24-911f-d8308da4f16c",
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install --upgrade pinecone-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "080eb155-60f9-4cea-9f15-c9c204546610",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "#Initialize the Pinecone control-plane client\n",
        "pc = Pinecone(\n",
        "    api_key=\"pcsk_r2pz5_UV2WuDc4A8KtaHcUPNca6fxptkvnFS14VU7rNCAB99kqmSDqAFSVdf4PwJgx5Mo\"\n",
        ")\n",
        "\n",
        "index_name = \"chatbot-index\"\n",
        "\n",
        "#create the index if non-existent \n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=384,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "        )\n",
        "    )\n",
        "    print(f\"Index '{index_name}' created.\")\n",
        "else:\n",
        "    print(f\"Index '{index_name}' already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f330c0b4-9601-4816-8047-75564cdbd84f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pinecone import Pinecone, ServerlessSpec, Index\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "#control plane to create or check index\n",
        "pc = Pinecone(\n",
        "    api_key=\"pcsk_r2pz5_UV2WuDc4A8KtaHcUPNca6fxptkvnFS14VU7rNCAB99kqmSDqAFSVdf4PwJgx5Mo\"\n",
        ")\n",
        "\n",
        "index_name = \"chatbot-index\"\n",
        "\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=384,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "        )\n",
        "    )\n",
        "    print(f\"Index '{index_name}' created!\")\n",
        "else:\n",
        "    print(f\"Index '{index_name}' already exists.\")\n",
        "\n",
        "# data plane: desc, connect, upsert\n",
        "desc = pc.describe_index(index_name)\n",
        "host = desc.host\n",
        "index = Index(\n",
        "    api_key=\"pcsk_r2pz5_UV2WuDc4A8KtaHcUPNca6fxptkvnFS14VU7rNCAB99kqmSDqAFSVdf4PwJgx5Mo\",\n",
        "    host=host\n",
        ")\n",
        "\n",
        "# loading\n",
        "with open('files/embeddings.pkl', 'rb') as f:\n",
        "    embeddings = pickle.load(f)\n",
        "\n",
        "# upsert\n",
        "for file_name, vector in embeddings.items():\n",
        "    if isinstance(vector, np.ndarray):\n",
        "        vector = vector.tolist()\n",
        "    index.upsert([(file_name, vector)])\n",
        "\n",
        "print(\"Embeddings uploaded successfully!\")\n",
        "\n",
        "# Query\n",
        "query_vector = np.random.rand(384).tolist()\n",
        "results = index.query(vector=query_vector, top_k=5, include_metadata=True)\n",
        "\n",
        "print(\"Search Results:\")\n",
        "for match in results[\"matches\"]:\n",
        "    print(f\"ID: {match['id']}, Score: {match['score']}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
