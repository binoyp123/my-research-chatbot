{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b133ccf1-9253-45bf-8b5e-c8bcb83cf8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in /home/bmp166/.local/lib/python3.12/site-packages (3.3.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/bmp166/.local/lib/python3.12/site-packages (from sentence-transformers) (4.47.1)\n",
      "Requirement already satisfied: tqdm in /usr/lib/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/bmp166/.local/lib/python3.12/site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/lib/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in /usr/lib/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/bmp166/.local/lib/python3.12/site-packages (from sentence-transformers) (0.27.0)\n",
      "Requirement already satisfied: Pillow in /usr/lib/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /usr/lib/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/lib/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/lib/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/lib/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/lib/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: networkx in /usr/lib/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/lib/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/lib/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/lib/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/bmp166/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/bmp166/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/lib/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/lib/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.7.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /home/bmp166/.local/lib/python3.12/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/lib/anaconda3/lib/python3.12/site-packages (from openai) (2.32.2)\n",
      "Requirement already satisfied: tqdm in /usr/lib/anaconda3/lib/python3.12/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: aiohttp in /usr/lib/anaconda3/lib/python3.12/site-packages (from openai) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai) (2024.7.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/lib/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/lib/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/lib/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/lib/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (1.9.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd34e023-eec7-42cb-a570-3e211f231584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries are installed successfully!\n"
     ]
    }
   ],
   "source": [
    "import sentence_transformers\n",
    "import openai\n",
    "\n",
    "print(\"Libraries are installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ab0b8d-6bd9-40f2-a2cd-58ef575601cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in /home/bmp166/.local/lib/python3.12/site-packages (3.3.1)\n",
      "Requirement already satisfied: pinecone-client in /home/bmp166/.local/lib/python3.12/site-packages (5.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/bmp166/.local/lib/python3.12/site-packages (from sentence-transformers) (4.47.1)\n",
      "Requirement already satisfied: tqdm in /usr/lib/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/bmp166/.local/lib/python3.12/site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/lib/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in /usr/lib/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/bmp166/.local/lib/python3.12/site-packages (from sentence-transformers) (0.27.0)\n",
      "Requirement already satisfied: Pillow in /usr/lib/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /usr/lib/anaconda3/lib/python3.12/site-packages (from pinecone-client) (2024.7.4)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /home/bmp166/.local/lib/python3.12/site-packages (from pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /home/bmp166/.local/lib/python3.12/site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/lib/anaconda3/lib/python3.12/site-packages (from pinecone-client) (4.11.0)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /usr/lib/anaconda3/lib/python3.12/site-packages (from pinecone-client) (2.2.2)\n",
      "Requirement already satisfied: filelock in /usr/lib/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/lib/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/lib/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/lib/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.2)\n",
      "Requirement already satisfied: networkx in /usr/lib/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/bmp166/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/lib/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/lib/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/lib/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/bmp166/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/bmp166/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/lib/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/lib/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Index 'chatbot-index' already exists.\n",
      "Upserted 1 chunks for file: Matlab notes  by Isaiah.txt\n",
      "Upserted 3 chunks for file: Design of 4-Winged Ornithopter by Sean Piscetelli.txt\n",
      "Upserted 19 chunks for file: README.txt\n",
      "Upserted 1 chunks for file: clion-log.txt\n",
      "Upserted 1 chunks for file: ReadMe_igVortex.txt\n",
      "Upserted 54 chunks for file: De Manabendra, 2024, Bio-inspired Flapping Wing Aerodynamics A Review.txt\n",
      "Upserted 4 chunks for file: Python manual.txt\n",
      "Upserted 1 chunks for file: output(m=21).txt\n",
      "Upserted 1 chunks for file: Flapping Wing.txt\n",
      "Upserted 5 chunks for file: Development of Vortices in Airplane.txt\n",
      "Upserted 27 chunks for file: A simple vortex approach to complex two wing unsteady flapping problems in 2D applied to insect flight study.txt\n",
      "Upserted 23 chunks for file: Dickinson, Lehman, Sane, 1999, Wing Rotation and the Aerodynamic Basis of Insect Flight, science.284.5422.1954.txt\n",
      "Upserted 1 chunks for file: out.txt\n",
      "Upserted 1 chunks for file: clion-environment.txt\n",
      "Upserted 5 chunks for file: Conda Environment Setup, Ashrit, 2022.txt\n",
      "Upserted 1 chunks for file: TargetDirectories.txt\n",
      "Upserted 9 chunks for file: CMakeCache.txt\n",
      "Upserted 12 chunks for file: output.txt\n",
      "Upserted 2 chunks for file: 2DManual.txt\n",
      "Upserted 5 chunks for file: 3D_Manual.txt\n",
      "Upserted 52 chunks for file: Sane, 2004, The aerodynamics of insect flight.txt\n",
      "Upserted 21 chunks for file: Denda, 2015, A Vortex Approach for Unsteady Insect Flight Analysis in 2-D.txt\n",
      "Upserted 1 chunks for file: Ornithopter design.txt\n",
      "Upserted 306 chunks for file: Form and Function of Insect Wings, Grodnitsky, 1999_i.txt\n",
      "Upserted 2 chunks for file: Python Manual for MacOS.txt\n",
      "Upserted 1 chunks for file: cleaned_BStripElongated.m\n",
      "Upserted 1 chunks for file: cleaned_dfDtableG.m\n",
      "Upserted 1 chunks for file: cleaned_igmeshR.m\n",
      "Upserted 1 chunks for file: cleaned_igcamberMESH.m\n",
      "Upserted 1 chunks for file: cleaned_dfVELF.m\n",
      "Upserted 1 chunks for file: cleaned_DtTB.m\n",
      "Upserted 2 chunks for file: cleaned_tbs5Mesh.m\n",
      "Upserted 1 chunks for file: cleaned_CElem_g6.m\n",
      "Upserted 1 chunks for file: cleaned_dfDtableB.m\n",
      "Upserted 2 chunks for file: cleaned_igwing2global.m\n",
      "Upserted 1 chunks for file: cleaned_dftableG.m\n",
      "Upserted 1 chunks for file: cleaned_igplotVortexw.m\n",
      "Upserted 1 chunks for file: cleaned_assembleMatrix.m\n",
      "Upserted 1 chunks for file: cleaned_igsolution.m\n",
      "Upserted 1 chunks for file: cleaned_wingMotionNCB.m\n",
      "Upserted 2 chunks for file: cleaned_tbvelBbyW.m\n",
      "Upserted 1 chunks for file: cleaned_DtableUpSTailB_2.m\n",
      "Upserted 1 chunks for file: cleaned_DtableUpSTailB.m\n",
      "Upserted 2 chunks for file: cleaned_igVELOCITYF.m\n",
      "Upserted 1 chunks for file: cleaned_slimpulse_tr.m\n",
      "Upserted 6 chunks for file: cleaned_igVortex.m\n",
      "Upserted 1 chunks for file: cleaned_crossMatrixCoef.m\n",
      "Upserted 1 chunks for file: cleaned_DcosUpTailG.m\n",
      "Upserted 1 chunks for file: cleaned_DcosTailG_2.m\n",
      "Upserted 9 chunks for file: cleaned_idragonfly_debug.m\n",
      "Upserted 1 chunks for file: cleaned_cosUpTailG_2.m\n",
      "Upserted 1 chunks for file: cleaned_dftableB.m\n",
      "Upserted 1 chunks for file: cleaned_ignVelocityw2.m\n",
      "Upserted 1 chunks for file: cleaned_DcosUpTailB_2.m\n",
      "Upserted 1 chunks for file: cleaned_cosUpTailB_2.m\n",
      "Upserted 1 chunks for file: cleaned_projectile.m\n",
      "Upserted 1 chunks for file: cleaned_ignVelocityw.m\n",
      "Upserted 1 chunks for file: cleaned_dfplotVortexw.m\n",
      "Upserted 1 chunks for file: cleaned_limpulse.m\n",
      "Upserted 1 chunks for file: cleaned_chordPath_d.m\n",
      "Upserted 1 chunks for file: cleaned_dfairfoilV.m\n",
      "Upserted 1 chunks for file: cleaned_igndData.m\n",
      "Upserted 1 chunks for file: cleaned_igforceMoment.m\n",
      "Upserted 2 chunks for file: cleaned_dfairfoilM.m\n",
      "Upserted 1 chunks for file: cleaned_tableUpSTailB.m\n",
      "Upserted 1 chunks for file: cleaned_dfforceMoment.m\n",
      "Upserted 1 chunks for file: cleaned_tableG.m\n",
      "Upserted 1 chunks for file: cleaned_cosTailB.m\n",
      "Upserted 1 chunks for file: cleaned_wingMotionB.m\n",
      "Upserted 1 chunks for file: cleaned_yRotate.m\n",
      "Upserted 1 chunks for file: cleaned_L2R.m\n",
      "Upserted 1 chunks for file: cleaned_DtableG.m\n",
      "Upserted 1 chunks for file: cleaned_wingMotion.m\n",
      "Upserted 1 chunks for file: cleaned_igconvect.m\n",
      "Upserted 1 chunks for file: cleaned_SOLVER.m\n",
      "Upserted 1 chunks for file: cleaned_igcMESH.m\n",
      "Upserted 1 chunks for file: cleaned_VORTEXm.m\n",
      "Upserted 2 chunks for file: cleaned_MotionPath.m\n",
      "Upserted 1 chunks for file: cleaned_cosTailB_2.m\n",
      "Upserted 1 chunks for file: cleaned_dfvelocity.m\n",
      "Upserted 1 chunks for file: cleaned_tbshedB.m\n",
      "Upserted 1 chunks for file: cleaned_tbplotWB.m\n",
      "Upserted 1 chunks for file: cleaned_sinmovie.m\n",
      "Upserted 1 chunks for file: cleaned_tableSTailB_2.m\n",
      "Upserted 1 chunks for file: cleaned_tbdivideGAM.m\n",
      "Upserted 1 chunks for file: cleaned_offset_g6.m\n",
      "Upserted 1 chunks for file: cleaned_centerSN.m\n",
      "Upserted 1 chunks for file: cleaned_BElem.m\n",
      "Upserted 1 chunks for file: cleaned_tblrL2G_2.m\n",
      "Upserted 1 chunks for file: cleaned_wingPathL.m\n",
      "Upserted 1 chunks for file: cleaned_igVELF.m\n",
      "Upserted 1 chunks for file: cleaned_igairfoilV.m\n",
      "Upserted 2 chunks for file: cleaned_tbndData.m\n",
      "Upserted 1 chunks for file: cleaned_tblrsetMatrix.m\n",
      "Upserted 1 chunks for file: cleaned_BRelemLoc.m\n",
      "Upserted 1 chunks for file: cleaned_DcTG.m\n",
      "Upserted 1 chunks for file: cleaned_iginData.m\n",
      "Upserted 1 chunks for file: cleaned_tbsolution.m\n",
      "Upserted 1 chunks for file: cleaned_cosTailG_2.m\n",
      "Upserted 1 chunks for file: cleaned_DtableSTailG_2.m\n",
      "Upserted 1 chunks for file: cleaned_DcTB.m\n",
      "Upserted 1 chunks for file: cleaned_dfndData.m\n",
      "Upserted 1 chunks for file: cleaned_tbvelBbyT.m\n",
      "Upserted 1 chunks for file: cleaned_borderSN.m\n",
      "Upserted 1 chunks for file: cleaned_CElem.m\n",
      "Upserted 1 chunks for file: cleaned_velVortex.m\n",
      "Upserted 1 chunks for file: cleaned_tbassembleMatrix.m\n",
      "Upserted 1 chunks for file: cleaned_DtableB.m\n",
      "Upserted 1 chunks for file: cleaned_SaveFigInBackground.m\n",
      "Upserted 1 chunks for file: cleaned_igimpulses.m\n",
      "Upserted 1 chunks for file: cleaned_tblrL2T_2.m\n",
      "Upserted 7 chunks for file: cleaned_tombo.m\n",
      "Upserted 2 chunks for file: cleaned_g5.m\n",
      "Upserted 1 chunks for file: cleaned_dfconvect.m\n",
      "Upserted 1 chunks for file: cleaned_tableB.m\n",
      "Upserted 1 chunks for file: cleaned_uNormal.m\n",
      "Upserted 3 chunks for file: cleaned_igVortex_manual.m\n",
      "Upserted 1 chunks for file: cleaned_dfnVelocityw.m\n",
      "Upserted 1 chunks for file: cleaned_wingMotionNC.m\n",
      "Upserted 1 chunks for file: cleaned_chordPathTail.m\n",
      "Upserted 8 chunks for file: cleaned_idragonfly1.m\n",
      "Upserted 1 chunks for file: cleaned_center_g6.m\n",
      "Upserted 2 chunks for file: cleaned_igairfoilM.m\n",
      "Upserted 2 chunks for file: cleaned_g6.m\n",
      "Upserted 1 chunks for file: cleaned_tblrmassL2GT.m\n",
      "Upserted 1 chunks for file: cleaned_cosTailG.m\n",
      "Upserted 1 chunks for file: cleaned_dfVELOCITYF.m\n",
      "Upserted 8 chunks for file: cleaned_Copy_of_idragonfly.m\n",
      "Upserted 1 chunks for file: cleaned_Camber.m\n",
      "Upserted 1 chunks for file: cleaned_dfsolution.m\n",
      "Upserted 1 chunks for file: cleaned_tableUpSTailG.m\n",
      "Upserted 1 chunks for file: cleaned_tbwingPathNC.m\n",
      "Upserted 1 chunks for file: cleaned_tbconvW.m\n",
      "Upserted 1 chunks for file: cleaned_DtableUpSTailG.m\n",
      "Upserted 1 chunks for file: cleaned_dfwing2FRT.m\n",
      "Upserted 1 chunks for file: cleaned_cosUpTailG.m\n",
      "Upserted 1 chunks for file: cleaned_Wing.m\n",
      "Upserted 1 chunks for file: cleaned_DtableSTailG.m\n",
      "Upserted 1 chunks for file: cleaned_plot2Elm.m\n",
      "Upserted 1 chunks for file: cleaned_igplotVelocity.m\n",
      "Upserted 1 chunks for file: cleaned_tbcrossvelBbyT.m\n",
      "Upserted 2 chunks for file: cleaned_tbforceMoment.m\n",
      "Upserted 1 chunks for file: cleaned_dpDtableB.m\n",
      "Upserted 1 chunks for file: cleaned_DtableSTailB_2.m\n",
      "Upserted 1 chunks for file: cleaned_aimpulse.m\n",
      "Upserted 1 chunks for file: cleaned_selfMatrixCoef.m\n",
      "Upserted 1 chunks for file: cleaned_BRelem.m\n",
      "Upserted 1 chunks for file: cleaned_DtTG.m\n",
      "Upserted 0 chunks for file: cleaned_tomboTester.m\n",
      "Upserted 1 chunks for file: cleaned_sinusoidal.m\n",
      "Upserted 1 chunks for file: cleaned_tableUpSTailG_2.m\n",
      "Upserted 2 chunks for file: cleaned_g5Mesh.m\n",
      "Upserted 1 chunks for file: cleaned_BElem_g6.m\n",
      "Upserted 2 chunks for file: cleaned_tbvelWbyT.m\n",
      "Upserted 1 chunks for file: cleaned_WingBorder.m\n",
      "Upserted 1 chunks for file: cleaned_CRnodes.m\n",
      "Upserted 1 chunks for file: cleaned_igmatrixCoef.m\n",
      "Upserted 1 chunks for file: cleaned_tTG.m\n",
      "Upserted 1 chunks for file: cleaned_dfplotVelocity.m\n",
      "Upserted 1 chunks for file: cleaned_tbcrossMatrix.m\n",
      "Upserted 1 chunks for file: cleaned_tbwingPathTail.m\n",
      "Upserted 1 chunks for file: cleaned_DcosTailB_2.m\n",
      "Upserted 1 chunks for file: cleaned_tbwingPathNCL.m\n",
      "Upserted 1 chunks for file: cleaned_dpsimpulseWT.m\n",
      "Upserted 1 chunks for file: cleaned_tbwingM.m\n",
      "Upserted 1 chunks for file: cleaned_tableUpSTailB_2.m\n",
      "Upserted 1 chunks for file: cleaned_center.m\n",
      "Upserted 1 chunks for file: cleaned_Triangle.m\n",
      "Upserted 1 chunks for file: cleaned_saimpulse_tr.m\n",
      "Upserted 1 chunks for file: cleaned_wingPath.m\n",
      "Upserted 1 chunks for file: cleaned_tblrL2G_1.m\n",
      "Upserted 2 chunks for file: cleaned_dfwing2global.m\n",
      "Upserted 1 chunks for file: cleaned_dptableB.m\n",
      "Upserted 1 chunks for file: cleaned_plot3Elem.m\n",
      "Upserted 1 chunks for file: cleaned_dfmeshR.m\n",
      "Upserted 1 chunks for file: cleaned_DtableUpSTailG_2.m\n",
      "Upserted 1 chunks for file: cleaned_tbaddWake.m\n",
      "Upserted 1 chunks for file: cleaned_cTB.m\n",
      "Upserted 1 chunks for file: cleaned_tableSTailG_2.m\n",
      "Upserted 1 chunks for file: cleaned_tbvelWbyW.m\n",
      "Upserted 1 chunks for file: cleaned_PitchPlot.m\n",
      "Upserted 1 chunks for file: cleaned_cTG.m\n",
      "Upserted 1 chunks for file: cleaned_DECOMP.m\n",
      "Upserted 8 chunks for file: cleaned_idragonfly.m\n",
      "Upserted 1 chunks for file: cleaned_borderSN_g6.m\n",
      "Upserted 2 chunks for file: cleaned_tbnvelTbyW.m\n",
      "Upserted 2 chunks for file: cleaned_g6Mesh.m\n",
      "Upserted 1 chunks for file: cleaned_tbtranslate.m\n",
      "Upserted 1 chunks for file: cleaned_plot2Elm_g6.m\n",
      "Upserted 1 chunks for file: cleaned_BStrip.m\n",
      "Upserted 1 chunks for file: cleaned_dfimpulses.m\n",
      "Upserted 1 chunks for file: cleaned_igplotMVortexw.m\n",
      "Upserted 1 chunks for file: cleaned_centerSN_g6.m\n",
      "Upserted 1 chunks for file: cleaned_tableSTailG.m\n",
      "Upserted 1 chunks for file: cleaned_tblrswingNVs.m\n",
      "Upserted 1 chunks for file: cleaned_DcosUpTailG_2.m\n",
      "Upserted 1 chunks for file: cleaned_tbvelBbyTMatrix.m\n",
      "Upserted 1 chunks for file: cleaned_DcosUpTailB.m\n",
      "Upserted 1 chunks for file: cleaned_DcosTailB.m\n",
      "Upserted 2 chunks for file: cleaned_s5.m\n",
      "Upserted 1 chunks for file: cleaned_dfchordPath.m\n",
      "Upserted 1 chunks for file: cleaned_DtableSTailB.m\n",
      "Upserted 1 chunks for file: cleaned_tbplotGAM.m\n",
      "Upserted 1 chunks for file: cleaned_plot2Elem.m\n",
      "Upserted 1 chunks for file: cleaned_limpulsew.m\n",
      "Upserted 1 chunks for file: cleaned_DcosTailG.m\n",
      "Upserted 1 chunks for file: cleaned_dfplotMVortexw.m\n",
      "Upserted 1 chunks for file: cleaned_WingTotal.m\n",
      "Upserted 1 chunks for file: cleaned_cosUpTailB.m\n",
      "Upserted 1 chunks for file: cleaned_dpDtableG.m\n",
      "Upserted 1 chunks for file: cleaned_dptableG.m\n",
      "Upserted 1 chunks for file: cleaned_offset.m\n",
      "Upserted 1 chunks for file: cleaned_tbsimpulseWT.m\n",
      "Upserted 2 chunks for file: cleaned_mVORTEX.m\n",
      "Upserted 1 chunks for file: cleaned_WingCenter.m\n",
      "Upserted 1 chunks for file: cleaned_tTB.m\n",
      "Upserted 1 chunks for file: cleaned_dfinData.m\n",
      "Upserted 1 chunks for file: cleaned_tbassemblevelBbyT.m\n",
      "Upserted 1 chunks for file: cleaned_tableSTailB.m\n",
      "Upserted 1 chunks for file: cleaned_igvelocity.m\n",
      "Upserted 1 chunks for file: cleaned_Camber2.m\n",
      "All chunks upserted to Pinecone successfully!\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers pinecone-client\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone, ServerlessSpec, Index\n",
    "\n",
    "\n",
    "# setup\n",
    "YOUR_API_KEY = \"pcsk_r2pz5_UV2WuDc4A8KtaHcUPNca6fxptkvnFS14VU7rNCAB99kqmSDqAFSVdf4PwJgx5Mo\"  # <-- Replace with your actual Pinecone key\n",
    "INDEX_NAME   = \"chatbot-index\"          \n",
    "\n",
    "# cleaned dir paths\n",
    "TXT_CLEANED_DIR = './files/processed_txt_files'\n",
    "M_CLEANED_DIR   = './files/processed_m_files'\n",
    "\n",
    "\n",
    "# Initialize sentence transformers model \n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "#Connect to Pinecone \n",
    "\n",
    "pc = Pinecone(api_key=YOUR_API_KEY)\n",
    "\n",
    "#Create the index if not already present\n",
    "if INDEX_NAME not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=384,    \n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",  \n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "    print(f\"Index '{INDEX_NAME}' created!\")\n",
    "else:\n",
    "    print(f\"Index '{INDEX_NAME}' already exists.\")\n",
    "\n",
    "desc = pc.describe_index(INDEX_NAME)\n",
    "host = desc.host  \n",
    "\n",
    "index = Index(api_key=YOUR_API_KEY, host=host)\n",
    "\n",
    "\n",
    "# Helper function for Chunking \n",
    "\n",
    "def chunk_text(text, chunk_size=2000, overlap=200):\n",
    "    \"\"\"\n",
    "    Splits text into overlapping chunks of length `chunk_size`.\n",
    "    Overlap helps preserve context between consecutive chunks.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    text_length = len(text)\n",
    "\n",
    "    while start < text_length:\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start += (chunk_size - overlap)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "#Function to read files, chunk, embed, and upsert \n",
    "def upsert_folder(folder_path, file_extension, chunk_size=2000, overlap=200):\n",
    "    \"\"\"\n",
    "    Reads each file in `folder_path` that ends with `file_extension`,\n",
    "    splits into chunks, embeds each chunk, and upserts them to Pinecone.\n",
    "    \"\"\"\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(file_extension):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "          \n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "\n",
    "           \n",
    "            text_chunks = chunk_text(content, chunk_size=chunk_size, overlap=overlap)\n",
    "\n",
    "            #For each chunk, embed, & upsert\n",
    "            for i, chunk in enumerate(text_chunks):\n",
    "                chunk_id   = f\"{file_name}_chunk_{i}\"\n",
    "                embedding  = model.encode(chunk).tolist()\n",
    "                metadata   = {\n",
    "                    \"text\": chunk,\n",
    "                    \"original_file\": file_name,\n",
    "                    \"chunk_index\": i\n",
    "                }\n",
    "                index.upsert([(chunk_id, embedding, metadata)])\n",
    "\n",
    "            print(f\"Upserted {len(text_chunks)} chunks for file: {file_name}\")\n",
    "\n",
    "\n",
    "# Upsert both directories \n",
    "upsert_folder(TXT_CLEANED_DIR, '.txt', chunk_size=2000, overlap=200)\n",
    "upsert_folder(M_CLEANED_DIR, '.m',   chunk_size=2000, overlap=200)\n",
    "\n",
    "print(\"All chunks upserted to Pinecone successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be4534e1-cfd5-4f22-849e-2b5d3e07f36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: Dickinson, Lehman, Sane, 1999, Wing Rotation and the Aerodynamic Basis of Insect Flight, science.284.5422.1954.txt\n",
      "Score: 0.76667285\n",
      "No metadata available for this match.\n",
      "\n",
      "ID: Dickinson, Lehman, Sane, 1999, Wing Rotation and the Aerodynamic Basis of Insect Flight, science.284.5422.1954.txt_chunk_0\n",
      "Score: 0.76667285\n",
      "Chunk Text: research articles wing rotation and the aerodynamic basis of insect flight michael h dickinson1 fritzolaf lehmann2 sanjay p sane1 insects were the first animals to evolve active flight and remain unsu...\n",
      "\n",
      "ID: Dickinson, Lehman, Sane, 1999, Wing Rotation and the Aerodynamic Basis of Insect Flight, science.284.5422.1954.txt_chunk_22\n",
      "Score: 0.764329553\n",
      "Chunk Text: flapping wings suggest that the aerodynamics of insect flight may be explained by the interaction of three distinct yet interactive mechanisms delayed stall rotational circulation and wake capture whe...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_embedding = model.encode(\"Explain how wing rotation works for insect flight\").tolist()\n",
    "results = index.query(vector=query_embedding, top_k=3, include_metadata=True)\n",
    "\n",
    "for match in results[\"matches\"]:\n",
    "    print(f\"ID: {match['id']}\")\n",
    "    print(f\"Score: {match['score']}\")\n",
    "\n",
    "    \n",
    "    if \"metadata\" in match:\n",
    "        snippet = match[\"metadata\"].get(\"text\", \"\")\n",
    "        print(f\"Chunk Text: {snippet[:200]}...\\n\")\n",
    "    else:\n",
    "        print(\"No metadata available for this match.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a9cb40d-862b-484f-9643-5ae3aaedc14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /home/bmp166/.local/lib/python3.12/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/lib/anaconda3/lib/python3.12/site-packages (from openai) (2.32.2)\n",
      "Requirement already satisfied: tqdm in /usr/lib/anaconda3/lib/python3.12/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: aiohttp in /usr/lib/anaconda3/lib/python3.12/site-packages (from openai) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai) (2024.7.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/lib/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/lib/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/lib/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/lib/anaconda3/lib/python3.12/site-packages (from aiohttp->openai) (1.9.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2956c8bf-ecbf-4b85-98cc-c1cf55e428b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai==0.28.0 in /home/bmp166/.local/lib/python3.12/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/lib/anaconda3/lib/python3.12/site-packages (from openai==0.28.0) (2.32.2)\n",
      "Requirement already satisfied: tqdm in /usr/lib/anaconda3/lib/python3.12/site-packages (from openai==0.28.0) (4.66.4)\n",
      "Requirement already satisfied: aiohttp in /usr/lib/anaconda3/lib/python3.12/site-packages (from openai==0.28.0) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai==0.28.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai==0.28.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai==0.28.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai==0.28.0) (2024.7.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/lib/anaconda3/lib/python3.12/site-packages (from aiohttp->openai==0.28.0) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/anaconda3/lib/python3.12/site-packages (from aiohttp->openai==0.28.0) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/lib/anaconda3/lib/python3.12/site-packages (from aiohttp->openai==0.28.0) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/lib/anaconda3/lib/python3.12/site-packages (from aiohttp->openai==0.28.0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/lib/anaconda3/lib/python3.12/site-packages (from aiohttp->openai==0.28.0) (1.9.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai==0.28.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d00a37-447e-4225-99f2-f69d8a43c939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot ready! Type 'exit' or 'quit' to stop.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  \"Answer only based on the provided research data embeddings. If the information is not found, respond with: 'I don't know based on the research data provided.'\" What is the capital of france?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: I don't know based on the research data provided.\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  capital of india\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: New Delhi\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "def chatbot():\n",
    "    print(\"Chatbot ready! Type 'exit' or 'quit' to stop.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        #Embed the user's question\n",
    "        query_embedding = model.encode(user_input).tolist()\n",
    "\n",
    "        #Query Pinecone for top chunks\n",
    "        results = index.query(\n",
    "            vector=query_embedding, \n",
    "            top_k=3, \n",
    "            include_metadata=True\n",
    "        )\n",
    "\n",
    "        # gather chunk text\n",
    "        retrieved_chunks = []\n",
    "        for match in results[\"matches\"]:\n",
    "            if \"metadata\" in match:\n",
    "                chunk_text = match[\"metadata\"].get(\"text\", \"\")\n",
    "                retrieved_chunks.append(chunk_text)\n",
    "\n",
    "        context_text = \"\\n\\n\".join(retrieved_chunks)\n",
    "\n",
    "        # build the prompt\n",
    "        prompt = f\"\"\"\n",
    "        You are an expert assistant. Use the following context to answer the user's question.\n",
    "        Context:\n",
    "        {context_text}\n",
    "\n",
    "        Question:\n",
    "        {user_input}\n",
    "\n",
    "        Provide a helpful, concise answer:\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "                temperature=0.7,\n",
    "            )\n",
    "            answer = response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            answer = f\"Error calling OpenAI API: {e}\"\n",
    "\n",
    "        print(f\"Chatbot: {answer}\\n{'-'*60}\\n\")\n",
    "\n",
    "chatbot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828329d1-97f0-47ca-bde5-011401770441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ab78e-e4bc-4f61-9718-1516ccf00068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./files/embeddings.pkl', 'rb') as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "print(f\"Number of embeddings: {len(embeddings)}\")\n",
    "for file_name, embedding in list(embeddings.items())[:5]:\n",
    "    print(f\"File: {file_name}, Embedding Shape: {len(embedding)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84f6731-04c7-4fe5-82ef-5b126dca307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e75109-69ee-48fe-a837-c8de11b1b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=\"pcsk_r2pz5_UV2WuDc4A8KtaHcUPNca6fxptkvnFS14VU7rNCAB99kqmSDqAFSVdf4PwJgx5Mo\")\n",
    "\n",
    "index_name = \"chatbot-index\"\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(f\"Index {index_name} created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d041cf-2003-4e24-911f-d8308da4f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pinecone-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b62282-dedb-4965-834b-1826723a79ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "#Initialize the Pinecone control-plane client\n",
    "pc = Pinecone(\n",
    "    api_key=\"pcsk_r2pz5_UV2WuDc4A8KtaHcUPNca6fxptkvnFS14VU7rNCAB99kqmSDqAFSVdf4PwJgx5Mo\"\n",
    ")\n",
    "\n",
    "index_name = \"chatbot-index\"\n",
    "\n",
    "#create the index if non-existent \n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,         \n",
    "        metric=\"cosine\",       \n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",       \n",
    "            region=\"us-east-1\" \n",
    "        )\n",
    "    )\n",
    "    print(f\"Index '{index_name}' created.\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080eb155-60f9-4cea-9f15-c9c204546610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec, Index\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "#control plane to create or check index \n",
    "\n",
    "\n",
    "pc = Pinecone(\n",
    "    api_key=\"pcsk_r2pz5_UV2WuDc4A8KtaHcUPNca6fxptkvnFS14VU7rNCAB99kqmSDqAFSVdf4PwJgx5Mo\"\n",
    ")\n",
    "\n",
    "index_name = \"chatbot-index\"\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "    print(f\"Index '{index_name}' created!\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists.\")\n",
    "\n",
    "\n",
    "#data plane: desc, connect, upsert \n",
    "\n",
    "\n",
    "desc = pc.describe_index(index_name)\n",
    "host = desc.host  \n",
    "index = Index(\n",
    "    api_key=\"pcsk_r2pz5_UV2WuDc4A8KtaHcUPNca6fxptkvnFS14VU7rNCAB99kqmSDqAFSVdf4PwJgx5Mo\",\n",
    "    host=host\n",
    ")\n",
    "\n",
    "\n",
    "#loading\n",
    "with open('files/embeddings.pkl', 'rb') as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "#upsert\n",
    "for file_name, vector in embeddings.items():\n",
    "    if isinstance(vector, np.ndarray):\n",
    "        vector = vector.tolist()\n",
    "    index.upsert([(file_name, vector)])\n",
    "\n",
    "print(\"Embeddings uploaded successfully!\")\n",
    "\n",
    "\n",
    "# Query\n",
    "query_vector = np.random.rand(384).tolist()\n",
    "results = index.query(vector=query_vector, top_k=5, include_metadata=True)\n",
    "\n",
    "print(\"Search Results:\")\n",
    "for match in results[\"matches\"]:\n",
    "    print(f\"ID: {match['id']}, Score: {match['score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f330c0b4-9601-4816-8047-75564cdbd84f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
