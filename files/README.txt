cuda framework and setup in matlab vibhu iyer may 19 2022 contents 1 introduction 2 2 matlabmex setup 21 setting up matlab and mexc 22 beginning to work with mexc in c 23 hello world in mexc 231 compiling and using mexc code in matlab 24 creating vector addition in c and mexc 241 classifying inputs 242 checking input lengths 243 adding vectors together 25 remarks 2 2 2 3 3 4 4 5 7 8 3 nvcc setup for matlab 8 4 creating cuda code 41 basics of the cuda language 411 introduction to kernels 412 inputs and outputs to kernels 9 9 9 9 5 interfacing cuda with matlab 11 6 optimizations 11 7 utilizing cuda in flapping wing simulations 12 8 appendix a scripts used 12 1 cuda in matlab iyer page 2 code 1 introduction through this essay we will setup matlab to utilize cuda and c to efficiently speed up code to do so we will consider primarily a specific example adding to vectors andor matrices we will do this in three different ways traditional matlab scripting matlab with c and mexc and finally introducing cuda to efficiently use the gpu to speed up the process in each step code will be provided that achieves the desired effect this code will be built upon in the following sections it is highly advised to follow along with these code sections before beginning please make sure of the following you have a computer with matlab installed and a version after 2015 2018 or after is preferred if possible this is for compatibility with mexc and the parallel computing toolbox which had optimizations added in the 2018 version you have a c compiler installed on your computer such as visual studio 2019 is the most preferred version your computer has an nvidia gpu with cuda cores for example a relatively new rtx or gtx card will suffice as will a quadro series card make sure that the card in use has sufficient video memory while this will not be a large issue for now due to the relatively small sizes of data we will be working with it may play a role in the projects to come after completing the work within this tutorial a working knowledge of c is assumed on the side of the reader several concepts such as malloc free and pointers are used extensively within this tutorial and are integral to the entire usage of cuda and mexc cuda is a layer on top of c and mexc at least to the extent used here is used in terms of c i would suggest a basic understanding provided by courses such as 01198211 computer architecture or similar before progressing that said c syntax is quite similar to for example that of java it is possible to follow along without a complete grasp of those concepts 2 21 matlabmex setup setting up matlab and mexc mexc is a system that allows matlab to make use of c code and creates the interface between the two for this section a computer with a c compiler installed is necessary such as a visual studio edition to check if such a compiler is installed using the respective computer terminal and enter the command g version something similar to the following should print out gexe mingworg gcc6301 630 followed by some other lines if this prints out the system is ready for c code compilation and execution note that such commands can be run directly from within the matlab window using the system command for example we can run systemg version from within the matlab command window to achieve the same results but from within matlab itself this can be helpful to add commands directly into scripts or to reduce the need for running a separate terminal instance further note the use of quotation marks within the matlab code dialogue matlab require commands to the console to be strings 22 beginning to work with mexc in c matlab interfaces with mexc and c using matlab functions much like normal scripts any code written within mexc programs are compiled as functions to be used as normal functions within matlab the script begins with the following function header 1 2 3 void mexfunction int nlhs mxarray plhs int nrhs mxarray prhs code here cuda in matlab iyer page 3 note the four inputs to this function these inputs are broken down into two separate parts inputs to this function and outputs to this function we can think of them as such 1 int nlhs this is the number of outputs returned by the function in classical cstyle this is not part of the array definition itself 2 mxarray plhs this is the array of outputs note the pointer at the front this tells us that this is an array of pointers or a 2d array i believe this to be most easily thought of as a list of pointers or a pointer to a memory location representative of a list of pointers as such this could also be written as mxarray plhs in a more classical cstyle we will use this as the output instead of an output from the file itself this also allows for multiple different outputs 3 int nrhs this is an integer representative of the number of inputs similarly to nlhs this tells us the number of pointers held by the array in this case the prhs array this can be used to error check for the correct number of inputs or ouputs 4 mxarray prhs again this is the actual array of pointers representative of the inputs to this specific function this is useful but cannot simply be used as such each pointer must be retrieved to properly access information within further we must check each input for example if our two vectors in our case are the same length for edgecase conditions and return early from our function in such trigger conditions it may be easier to consider this function under similar yet easier to understand naming which can mek working with such functions easier note that changing function parameter names does not effect the function itself 1 2 3 void mexfunction int numoutputs mxarray outputs int numinputs mxarray inputs code here 23 hello world in mexc to begin let us simply create a starter hello world program for this we make use of the mexprintf function in the body of our program note that most mexc functions begin with either mx or mex in this case we are utilizing the mexc version of printf a classical printing function for c or c as such we can use the function mexprintfhello worldn to print out hello world to the matlab console note that this is the key difference mexprintf has the ability to print directly to the matlab command window while normal c printf can only be used in the terminal our entire program now looks like this 1 include mex h 2 3 4 5 void mexfunction int numoutputs mxarray outputs int numinputs mxarray inputs mexprintf test n note the inclusion of the mexh header file on top this allows us to make use of mexc functions 231 compiling and using mexc code in matlab mexc code must first be compiled before it can be used as a function in matlab first we save our file as a cpp file in this case we save our file as mexhelloworldcpp once our file is saved we can then run the following command from the matlab command window 1 mex mexhelloworld cpp cuda in matlab iyer page 4 doing so should produce output similar to the following 1 2 building with microsoft visual c 2019 mex completed successfully once this is done you will see a new file in your home directory similar to mexhelloworldmexw64 in this case the w64 specifies compilation to a windows x64 binary for different editions this will have different endings but will share the same name as your program itself for all intents and purposes we will be assuming that code is being written on such a machine and this guide will follow the windows x64 path the differences between operating systems should not play a large role in this process a note on the mexc compiler compiled files are placed in the current matlab folder root which can be slightly disorganized to help with this disorganization we can make use of the outdir compilation option to set the output folder for the mexw64 file note that we cannot specify file name but only the directory inside of which this file will be placed further matlab cannot use either m or mexw64 files in folders to get around this we can enter the following line either in the command window before beginning our work or put it at the top of our matlab script from which we will be running code from addpath genpath pwd 1 24 creating vector addition in c and mexc we can now begin adding to the body of this function for which we must first define all the necessary steps they are as follows 1 compute if the data is of the right type or not 2 compute the dimensions of our data here we will first begin by assuming that we are adding single numbers then add complexity first a vector then a matrix then a 3d array and so on this step may or may not be necessary depending on the task at hand 3 use c to compute the vectormatrix addition 4 populate return arrays and dump memory data as required by the program let us begin at the first of these steps matlab arrays are passed in as an array of mxarray pointers rather than normal computable numbers as such we must first check that these numbers are of the correct type that we want to use in this case either floats or doubles single or double precision floatingpoint numbers to do this we can make use of mexc library functions specifically we make use of the mxisdouble and mxissingle functions 241 classifying inputs let us begin by using these two to simply print out the type of structs passed into the program we can do this as follows 1 2 3 4 check if inputs exist if numinputs 0 mexerrmsgtxt wrong number of inputs 5 6 7 extract the first input as an mxarray pointer mxarray firstinput inputs 0 8 9 10 11 12 13 check if input is of float single double or unkown type if mxissingle firstinput mexprintf input of type floats n else if mxisdouble firstinput mexprintf input of type doubles n cuda in matlab 14 15 16 iyer page 5 else mexprintf input of unkown type n the first code block that of the input check sees if there are enough inputs provided see that if there are not enough inputs ie if there are 0 inputs then the function simply prints wrong number of inputs as an error message and then returns stopping the function from proceeding further we cannot simply use the return keyword here as this would not process outputs properly using the mexc function mexerrmsgtxt is a safety net for proper usage of functions and helps in debugging we can then get a pointer to our first array as an mxarray which is the foundation of the mexc system we use this pointer as inputs to many functions two of which are mxisdouble and mxissingle which are two special cases of the function mxisclass or mxgetclass here we use this to get the type of our function we can check that this works with the following matlab script 1 2 3 compiles program addpath genpath pwd mex mexfolder mexvecadd cpp outdir mexfolder 4 5 6 this should print double mexvecadd 0 7 8 9 this should print single mexvecadd single 0 10 11 12 this is the same as a c integer should print unkown type mexvecadd int32 0 13 14 15 this should be the edge case of not enough inputs mexvecadd resulting in the following output 1 2 3 4 5 6 7 building with microsoft visual c 2019 mex completed successfully input of type doubles input of type floats input of unkown type error using mexvecadd test 8 9 10 error in vecadd line 15 mexvecadd the first two lines being the output of the program for compilation of our scripts this is useful now when we are changing the script every run in final programs it is recommended to take out this line where possible note that the default for matlab is to work with double precision and as such in our program we will be dealing with these inputs as doubles 242 checking input lengths we can now classify our inputs and check their lengths for our vector addition program we are looking to add two different vectors therefore our program should take in two different inputs and any other case should be considered incorrect and throw some error we then check whether both arrays are of the type required double precision only if both are double precision do we then continue with the operations we want 1 2 check if inputs exist if numinputs 2 cuda in matlab mexerrmsgtxt wrong number of inputs 3 4 iyer page 6 5 6 7 8 extract the first and second input as an mxarray pointer mxarray firstinput inputs 0 mxarray secondinput inputs 1 9 10 11 12 13 check if the inputs are double precision if mxisdouble firstinput mxisdouble secondinput mexerrmsgtxt inputs are not of double precision now we must make sure that the size of the two arrays matches to do this we must check that the dimensions of both arrays are the same dimensions of mxarrays can be found using the mexc function mxgetnumberofdimensions and mxgetdimensions both of which take in an mxarray pointer the following code segment will print the number of dimensions then the values of each dimension 1 2 3 4 5 6 7 8 int numdimensions m x g e t n u m b e r o f d i m e n s i o n s firstinput size_t dimensions size_t mxgetdimensions firstinput mexprintf i dimensions detected n numdimensions mexprintf dimensions for int i 0 i numdimensions i mexprintf i dimensions i mexprintf n note the use of size_t the value returned by mxgetdimensions is an array of mwsize const values to get around this const limitation we can cast to an array of size_t we cannot use int as integers do not cover the full range of values required further fundamentally as stated by the documentation mwsize is equivalent to size_t the const limitation is also not necessarily a bad thing instead if we use const size_t dims this casting would not be necessary but is left to personal preference let us now do this with both of our input matrices to check that they have the same number of dimensions if they do not we can return with an error 1 2 3 if m x g e t n u m b e r o f d i m e n s i o n s firstinput m x g e t n u m b e r o f d i m e n s i o n s secondinput mexerrmsgtxt inputs do not have the same number of dimensions 4 5 int numdimensions m x g e t n u m b e r o f d i m e n s i o n s firstinput 6 7 8 size_t firstdims size_t mxgetdimensions firstinput size_t seconddims size_t mxgetdimensions secondinput 9 10 11 12 for int i 0 i numdimensions i if firstdims i seconddims i mexerrmsgtxt dimensions do not match now that we have our two matrices we can finally add them together in matlab all matrices regardless of dimensions are stored as a continuous array of memory such that each matrix contains all the memory of its dimensions multiplied together we can get this total number of elements more simply with the command mxgetnumberofelements which returns a single number that is the same as multiplying all the dimensions together once the number of elements has been found we can then use the functions mxgetdata to retreive the data as a pointer to the allocated memory region this returns void such that we can assign whichever type required however a safer method for numeric matrices such as the ones we are working with in this cuda in matlab iyer page 7 example is to use numericspecific methods such as mxgetdoubles which returns mxdouble which can easily be cast to double however to use such a function we must first include matrixh as well as compile with a newer more advanced version of mexc this can be done by including the flag r2018a in our compilation step our c code now looks like this 1 size_t numelem m x g e t n u m b e r o f e l e m e n t s firstinput 2 3 4 double in1 double mxgetdoubles firstinput double in2 double mxgetdoubles secondinput 5 6 7 8 9 10 prints both matrices one after the other for int i 0 i numelem i mexprintf f in1 i 11 12 13 14 15 mexprintf n for int i 0 i numelem i mexprintf f in2 i 16 17 mexprintf n and our matlab code looks like such 1 mex r2018a mexfolder mexvecadd cpp outdir mexfolder 2 3 4 5 matrix1 rand 1 10 matrix2 rand 1 10 6 7 mexvecadd matrix1 matrix2 243 adding vectors together this process is relatively simple we create a new double array of our final dimension size and populate it as required with a simple loop note that in order to create a new double array we assign it to the first output value in the outputs array we then pull the memory data from this array and modify it as necessary at some point in the body preferrably at the top where we begin our function we should also check to see if the number of outputs is what is wanted if it is not then we can return like if numoutputs 1 mexerrmsgtxtwrong number of outputs then our code is now as follows 1 2 double in1 double mxgetdoubles firstinput double in2 double mxgetdoubles secondinput 3 4 5 outputs 0 m x c r e a t e n u m e r i c a r r a y numdimensions firstdims mxdouble_class mxreal double out1 double mxgetdoubles outputs 0 6 7 8 9 10 11 for int i 0 i numelem i out1 i in1 i in2 i finally we can finish our matlab script to show the comparison between two vectors like so cuda in matlab 1 2 iyer page 8 compiles program mex r2018a mexfolder mexvecadd cpp outdir mexfolder 3 4 5 6 matrix1 rand 5 5 matrix2 rand 5 5 7 8 9 10 tic out1 mexvecadd matrix1 matrix2 toc 11 12 13 14 tic matrix1 matrix2 toc output should look similar to the following see the answer returned by the builtin addition method matrix1 matrix2 is exactly the same as that returned by our method 1 2 building with microsoft visual c 2019 mex completed successfully 3 4 out1 5 08111 10595 07100 09751 15346 6 7 8 9 10 04244 18571 09821 10992 15534 15759 14785 03782 01471 08834 11487 09030 12275 11704 10399 04862 10296 12236 07616 11304 11487 09030 12275 11704 10399 04862 10296 12236 07616 11304 11 12 elapsed time is 0002347 seconds 13 14 ans 15 08111 10595 07100 09751 15346 16 17 18 19 20 04244 18571 09821 10992 15534 15759 14785 03782 01471 08834 21 22 elapsed time is 0000257 seconds 25 remarks using the tic and toc methods we are able to show that the inbuilt method from matlab is orders of magnitude faster than our newly created mexc method however mexc allows us the flexibility to do much harder operations in much faster operation time than pure matlab code would allow functions like adding arrays are so fast in matlab as the functions themselves are executed in precompiled c binaries this allows fast execution of simple operations but slow execution of complicated custom ones written in matlab itself we can get around this with the mexc system see appendix a for the final completed c code 3 nvcc setup for matlab to begin let us set up the cuda compiler to work in matlab we begin with the same command as before that of systemnvcc version if this displays an unkown error or error message then cuda is not yet cuda in matlab iyer page 9 set up to work on the system on newer versions of matlab the nvcc compiler is preinstalled with matlab however it is worth looking into setting up cuda to work directly this will allow compilation outside of the matlab environment which can be useful for projects that do not involve matlab further the code that we will write is separate from matlab code itself this allows the creation of complex libraries that involve gpus but can be used by a multitude of different programs and languages like for example both matlab and python have support for cuda 4 creating cuda code 41 basics of the cuda language 411 introduction to kernels cuda is a layer built on top of existing c or c it is written in cu files which are then compiled using nvcc the nvidia cuda compiler cuda is built on the principal of kernels pieces of code that are run in parallel on the gpu kernels are called once with instructions on how many times to be run this is given using threads and blocks gpus will run cuda code in blocks each of which comprises of some number of threads we can therefore find the total number of instances that will run by multiplying the number of threads with the number of blocks the following is an example of a cuda call 1 2 cudaaddvectors numelements 1 gpuin1 gpuin2 gpuout1 numelements we can see that it is a kernel function call by the triple angle brackets on either side the two numbers that follow are the number of blocks and threads respectively here we can see that we are running this function in parallel numelements times which we get from numelements 1 if we had called this function with 1 numelements we would get the same number of runtimes but with different performance and repurcussions which will be discussed in a later section further we can see that it takes in 4 different inputs which will also be discussed in order to call such a cuda kernel first we must write one to do so we begin with our function header unlike mexc cuda kernels are not a defined function header instead they simply rely on a single keyword __global__ this means that we can use any function name and combination of inputs required for our specific kernel to work for our addition function we can name our function something along the lines of cudavecadd this gives us the following function header 1 2 3 __global__ void cudaaddvectors double in1 double in2 double out1 int numelements code here 412 inputs and outputs to kernels kernels take in inputs and outputs usually in the form of gpu pointers these are specialized pointers that point to locations in gpu memory instead of in normal memory locations this allows us to use them within a kernel efficiently in this case we have two input pointers one output pointer and one number telling us the maximum of these arrays defined by said pointers each of these input pointer would refer to our input matrices as defined in section 242 these matrices are stores as a linear array by matlab the output array would be an array of the same length as the inputs that length being our final input numelements inside our kernel we can now assume we are working on a single element in our array and treat our parallelization as such to get the element we are working on we can use three inbuilt variables within kernels these are threadidx and blockidx corresponding to the threads and blocks detailed above these tell us positions within the current block and are structs that change per thread running further we can use blockdim for the dimensions of each block those familiar with offset formulae such as those used in 2d arrays will recognize the following formula to compute the current index within our array cuda in matlab iyer page 10 1 int index threadidx x 2 blockidx x blockdim x 3 we can then compare this number to our maximum number to make sure we are within the bounds of our array we do this because it is possible that we have allocated enough threads and blocks to overflow our array consider the following case we have 24 elements so we allocated 5 blocks with 5 threads each therefore the last element is out of bounds and we must check for this this check is relatively simple 1 if i numelements return 2 3 this safety check returns if we are out of bounds cuda can also work in multiple dimensions such that we will have to do this check for all involved dimensions this is not necessary for the purposes of this guide but can be useful when working with specific data finally we can add our two arrays together this too is simple 1 out1 i in1 i in2 i 2 3 as we can see the entire kernel is not very complicated or very difficult to write the complexity comes from the area where this kernel is called there are multiple steps before such a kernel can be executed we must create our gpu memory pointers allocate them copy memory where necessary and then copy it back to the cpu side at the end such that it can really be used in an actual program finally we must free that gpu memory so that it can be used somewhere else we do this using built in cuda functions specifically we use the cuda versions of wellknown c functions for allocating and deallocating memory cudamalloc and cudafree we also make use of a specific cuda function for copying data from the cpu to the gpu or vice versa in cuda terminology the cpu is known as the host and the gpu is known as the device there can be multiple devices per host and we can also use host to host communication where necessary to copy memory from the host to the device or vice versa we make use of cudamemcpy our code to call the kernel now looks like the following 1 2 3 4 5 6 7 void cudavecadd double in1 double in2 double out1 int numelements double gpuin1 gpuin2 gpuout1 cudamalloc gpuin1 sizeof double numelements cudamalloc gpuin2 sizeof double numelements cudamalloc gpuout1 sizeof double numelements cudamemcpy gpuin1 in1 sizeof double numelements cudamemcpyhosttodevice cudamemcpy gpuin2 in2 sizeof double numelements cudamemcpyhosttodevice 8 cudaaddvectors numelements 1 gpuin1 gpuin2 gpuout1 numelements 9 10 cudamemcpy out1 gpuout1 sizeof double numelements cudamemcpydevicetohost 11 12 cudafree gpuin1 cudafree gpuin2 cudafree gpuout1 13 14 15 16 17 cuda in matlab iyer page 11 we have wrapped our kernel call in another function cudavecadd with the help of a header file we will be able to call this function from outside of this specific file allowing us to utilize our cuda kernels as library this function takes in very similar inputs as our kernel itself but with cpu pointers instead of gpu pointers we convert these to gpu pointers using cudamalloc note that the pointer itself is the same as it still points to some memory location the change is what memory location it points to we allocate all of our gpu sided arrays both inputs and the singular output and then copy the necessary data note that we do not copy the output over at the beginning just as we do not copy the inputs over at the end copying memory to and from the gpu and cpu takes a large portion of the runtime for such kernels and as such should be kept to a minimum as we are populating values and not reading for the output as we are not reading to return for the rest of this function we can skip copying the outputs before they are populated and similar for the inputs we now are only left with linking our cuda kernel with our mexc code changing where necessary and running our code in the matlab environment 5 interfacing cuda with matlab to interface cuda code with matlab we can call it from a mexc function in order to do this we must first compile our cuda code and then compile our mexc code using our cuda code to do this we define a header file for our cuda cu file and add our function headers when doing so we must also write the keyword extern this tells c that the given function exists in a separate file the header file will let us use the function after compilation to a obj file this header file looks like such 1 2 ifndef __addvectors_h__ define __addvectors_h__ 3 4 extern void addvectors double a double b double c int size 5 6 endif __addvectors_h__ now we can use this function in our mexvecaddcpp file first we include our new header file then replace our loop that added the vectors with our new function the code now looks like it does in appendix a we can now begin compiling to compile our code from within matlab we can run the following commands in order system nvcc c mexfolder mexcudavecadd cu o mexfolder mexcudavecadd obj 1 2 mex mexfolder mexvecadd cpp mexfolder mexcudavecadd obj lcudart l c program files nvidia gpu computing toolkit cuda v11 3 lib x64 r2018a outdir mexfolder 3 here we tell mexc to compile both of our files the mexfunction itself and the cuda code that we have written further we must tell mex where our cuda libraries are located we do this using the lcudart option specifying our directory with our cuda library for me this is c program files nvidia gpu computing toolkit cuda v11 3 lib x64 1 we specify this location with the l flag finally we must include as before the r2018a flag to make sure our code is compatible 6 optimizations first when we now run our code you may notice that it is much slower than the simple matlab code matlab uses optimized functions and libraries that multithread in the background making simple library functions like addition of vectors and matrices extremely fast however we can still optimize our cuda code to make cuda in matlab iyer page 12 it faster one of the easiest ways to do this is by changing around our block and thread sizes for example running with 1 thread per n blocks is much slower than a single block with n threads simply changing the order of our two input variables affords a 10x increase in performance from an average of 0428 seconds to 0045 seconds there are many variables that factor into the optimal combination of threads and blocks in general it is best to allocate threads in groups of 32 and around an even number of blocks and threads this tells us that we should take some square root to find optimal combinations of threads and blocks however this is not always necessary in many cases the speedup is not large enough to overcome the slowness of the square root function for computers instead we can use some given number of threads such as 512 and then calculate the number of necessary blocks as a function of n this would be either n512 1 or n512 depending on whether or not there is a remainder in most cases the former is enough but is not completely optimial i believe the error check is worth looking into this is factored into our new cuda function listed in appendix a 7 utilizing cuda in flapping wing simulations the flapping wing simulations are very computationallyheavy however many of these computations are done one at a time sequentially when they have no effect on each other one of the largest and most computationally intensive programs mvortexm tends to take lots of time when done sequentially further the actual math computed in mvortexm is significant to this cuda exercise as it is mostly done computationally on arrays we can take the code that has been written for matlab to carry out and rewrite it using mexc and c as well as cuda to be done all at once on the gpu instead while this is helpful the actual efficiency increase is based on the array size passed into the cuda kernel instead we can also carry out multiple computations of a mvortexm file in synchronously such that we are instead doing all the computations of a given file inside of its own cuda kernel cuda in ways of supporting this has made the program possible to use in terms of kernelwithinkernel execution however this is somewhat outside the scope of this tutorial to modify the current code begin with the mvortexm file which itself calls mexc versions of the same files which then call cuda libraries inbuilt in the same folders cuda kernels can be added and compiled in the way shown above 8 appendix a scripts used a code for mexvecaddcpp 1 2 3 include mex h include matrix h include mexcudavecadd h 4 5 6 7 void mexfunction int numoutputs mxarray outputs int numinputs mxarray inputs 8 9 10 11 12 check if inputs exist if numinputs 2 mexerrmsgtxt wrong number of inputs 13 14 if numoutputs 1 mexerrmsgtxt wrong number of outputs 15 16 17 18 extract the first and second input as an mxarray pointer mxarray firstinput inputs 0 mxarray secondinput inputs 1 cuda in matlab iyer page 13 19 check if the inputs are double precision if mxisdouble firstinput mxisdouble secondinput mexerrmsgtxt inputs are not of double precision 20 21 22 23 24 if m x g e t n u m b e r o f d i m e n s i o n s firstinput m x g e t n u m b e r o f d i m e n s i o n s secondinput mexerrmsgtxt inputs do not have the same number of dimensions 25 26 27 28 size_t numdimensions m x g e t n u m b e r o f d i m e n s i o n s firstinput 29 30 size_t firstdims size_t mxgetdimensions firstinput size_t seconddims size_t mxgetdimensions secondinput 31 32 33 for int i 0 i numdimensions i if firstdims i seconddims i mexerrmsgtxt dimensions do not match 34 35 36 37 38 size_t numelem m x g e t n u m b e r o f e l e m e n t s firstinput 39 40 double in1 double mxgetdoubles firstinput double in2 double mxgetdoubles secondinput 41 42 43 outputs 0 m x c r e a t e n u m e r i c a r r a y numdimensions firstdims mxdouble_class mxreal double out1 double mxgetdoubles outputs 0 44 45 46 47 48 addvectors in1 in2 out1 numelem 49 50 51 52 53 54 b code for cudavecaddcu 1 2 include mexcudavecadd h include mex h 3 4 5 6 7 8 9 10 11 __global__ void cudaaddvectors double in1 double in2 double out1 int numelements int i threadidx x blockidx x blockdim x if i numelements return double total 0 for int k i 10 k i 10 k total k out1 i total cuda in matlab 12 iyer page 14 13 14 15 16 17 18 19 20 21 void addvectors double in1 double in2 double out1 int numelements double gpuin1 gpuin2 gpuout1 cudamalloc gpuin1 sizeof double numelements cudamalloc gpuin2 sizeof double numelements cudamalloc gpuout1 sizeof double numelements cudamemcpy gpuin1 in1 sizeof double numelements cudamemcpyhosttodevice cudamemcpy gpuin2 in2 sizeof double numelements cudamemcpyhosttodevice 22 int threadsperblock 512 int numblocks numelements 512 23 24 25 if numelements 512 0 numblocks 26 27 28 29 cudaaddvectors numblocks threadsperblock gpuin1 gpuin2 gpuout1 numelements 30 31 cudamemcpy out1 gpuout1 sizeof double numelements cudamemcpydevicetohost 32 33 cudafree gpuin1 cudafree gpuin2 cudafree gpuout1 34 35 36 37