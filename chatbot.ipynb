{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf9e558-9a83-4872-9597-d398e3f74d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter kernel Python: /usr/lib/anaconda3/bin/python\n",
      "Found existing installation: openai 0.28.0\n",
      "Uninstalling openai-0.28.0:\n",
      "  Successfully uninstalled openai-0.28.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai==0.28.0\n",
      "  Using cached openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/lib/anaconda3/lib/python3.12/site-packages (from openai==0.28.0) (2.32.2)\n",
      "Requirement already satisfied: tqdm in /usr/lib/anaconda3/lib/python3.12/site-packages (from openai==0.28.0) (4.66.4)\n",
      "Requirement already satisfied: aiohttp in /usr/lib/anaconda3/lib/python3.12/site-packages (from openai==0.28.0) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai==0.28.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai==0.28.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai==0.28.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/anaconda3/lib/python3.12/site-packages (from requests>=2.20->openai==0.28.0) (2024.7.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/lib/anaconda3/lib/python3.12/site-packages (from aiohttp->openai==0.28.0) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/anaconda3/lib/python3.12/site-packages (from aiohttp->openai==0.28.0) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/lib/anaconda3/lib/python3.12/site-packages (from aiohttp->openai==0.28.0) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/lib/anaconda3/lib/python3.12/site-packages (from aiohttp->openai==0.28.0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/lib/anaconda3/lib/python3.12/site-packages (from aiohttp->openai==0.28.0) (1.9.3)\n",
      "Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: openai\n",
      "\u001b[33m  WARNING: The script openai is installed in '/home/bmp166/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed openai-0.28.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "print(\"Jupyter kernel Python:\", sys.executable)\n",
    "\n",
    "!{sys.executable} -m pip uninstall openai -y\n",
    "!{sys.executable} -m pip install openai==0.28.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4567b766-f12a-4697-9456-8be647f83038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /usr/lib/anaconda3/bin/python\n",
      "OpenAI version: 0.28.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import openai\n",
    "import os\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone, ServerlessSpec, Index\n",
    "\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"OpenAI version:\", openai.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af37a721-a104-4326-9fec-503ec4b43a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'chatbot-index' already exists.\n",
      "Upserted 1 chunks for file: Matlab notes  by Isaiah.txt\n",
      "Upserted 3 chunks for file: Design of 4-Winged Ornithopter by Sean Piscetelli.txt\n",
      "Upserted 19 chunks for file: README.txt\n",
      "Upserted 1 chunks for file: clion-log.txt\n",
      "Upserted 1 chunks for file: ReadMe_igVortex.txt\n",
      "Upserted 54 chunks for file: De Manabendra, 2024, Bio-inspired Flapping Wing Aerodynamics A Review.txt\n",
      "Upserted 4 chunks for file: Python manual.txt\n",
      "Upserted 1 chunks for file: output(m=21).txt\n",
      "Upserted 1 chunks for file: Flapping Wing.txt\n",
      "Upserted 5 chunks for file: Development of Vortices in Airplane.txt\n",
      "Upserted 27 chunks for file: A simple vortex approach to complex two wing unsteady flapping problems in 2D applied to insect flight study.txt\n",
      "Upserted 23 chunks for file: Dickinson, Lehman, Sane, 1999, Wing Rotation and the Aerodynamic Basis of Insect Flight, science.284.5422.1954.txt\n",
      "Upserted 1 chunks for file: out.txt\n",
      "Upserted 1 chunks for file: clion-environment.txt\n",
      "Upserted 5 chunks for file: Conda Environment Setup, Ashrit, 2022.txt\n",
      "Upserted 1 chunks for file: TargetDirectories.txt\n",
      "Upserted 9 chunks for file: CMakeCache.txt\n",
      "Upserted 12 chunks for file: output.txt\n",
      "Upserted 2 chunks for file: 2DManual.txt\n",
      "Upserted 5 chunks for file: 3D_Manual.txt\n",
      "Upserted 52 chunks for file: Sane, 2004, The aerodynamics of insect flight.txt\n",
      "Upserted 21 chunks for file: Denda, 2015, A Vortex Approach for Unsteady Insect Flight Analysis in 2-D.txt\n",
      "Upserted 1 chunks for file: Ornithopter design.txt\n",
      "Upserted 306 chunks for file: Form and Function of Insect Wings, Grodnitsky, 1999_i.txt\n",
      "Upserted 2 chunks for file: Python Manual for MacOS.txt\n",
      "Upserted 1 chunks for file: cleaned_BStripElongated.m\n",
      "Upserted 1 chunks for file: cleaned_dfDtableG.m\n",
      "Upserted 1 chunks for file: cleaned_igmeshR.m\n",
      "Upserted 1 chunks for file: cleaned_igcamberMESH.m\n",
      "Upserted 1 chunks for file: cleaned_dfVELF.m\n",
      "Upserted 1 chunks for file: cleaned_DtTB.m\n",
      "Upserted 2 chunks for file: cleaned_tbs5Mesh.m\n",
      "Upserted 1 chunks for file: cleaned_CElem_g6.m\n",
      "Upserted 1 chunks for file: cleaned_dfDtableB.m\n",
      "Upserted 2 chunks for file: cleaned_igwing2global.m\n",
      "Upserted 1 chunks for file: cleaned_dftableG.m\n",
      "Upserted 1 chunks for file: cleaned_igplotVortexw.m\n",
      "Upserted 1 chunks for file: cleaned_assembleMatrix.m\n",
      "Upserted 1 chunks for file: cleaned_igsolution.m\n",
      "Upserted 1 chunks for file: cleaned_wingMotionNCB.m\n",
      "Upserted 2 chunks for file: cleaned_tbvelBbyW.m\n",
      "Upserted 1 chunks for file: cleaned_DtableUpSTailB_2.m\n",
      "Upserted 1 chunks for file: cleaned_DtableUpSTailB.m\n",
      "Upserted 2 chunks for file: cleaned_igVELOCITYF.m\n",
      "Upserted 1 chunks for file: cleaned_slimpulse_tr.m\n",
      "Upserted 6 chunks for file: cleaned_igVortex.m\n",
      "Upserted 1 chunks for file: cleaned_crossMatrixCoef.m\n",
      "Upserted 1 chunks for file: cleaned_DcosUpTailG.m\n",
      "Upserted 1 chunks for file: cleaned_DcosTailG_2.m\n",
      "Upserted 9 chunks for file: cleaned_idragonfly_debug.m\n",
      "Upserted 1 chunks for file: cleaned_cosUpTailG_2.m\n",
      "Upserted 1 chunks for file: cleaned_dftableB.m\n",
      "Upserted 1 chunks for file: cleaned_ignVelocityw2.m\n",
      "Upserted 1 chunks for file: cleaned_DcosUpTailB_2.m\n",
      "Upserted 1 chunks for file: cleaned_cosUpTailB_2.m\n",
      "Upserted 1 chunks for file: cleaned_projectile.m\n",
      "Upserted 1 chunks for file: cleaned_ignVelocityw.m\n",
      "Upserted 1 chunks for file: cleaned_dfplotVortexw.m\n",
      "Upserted 1 chunks for file: cleaned_limpulse.m\n",
      "Upserted 1 chunks for file: cleaned_chordPath_d.m\n",
      "Upserted 1 chunks for file: cleaned_dfairfoilV.m\n",
      "Upserted 1 chunks for file: cleaned_igndData.m\n",
      "Upserted 1 chunks for file: cleaned_igforceMoment.m\n",
      "Upserted 2 chunks for file: cleaned_dfairfoilM.m\n",
      "Upserted 1 chunks for file: cleaned_tableUpSTailB.m\n",
      "Upserted 1 chunks for file: cleaned_dfforceMoment.m\n",
      "Upserted 1 chunks for file: cleaned_tableG.m\n",
      "Upserted 1 chunks for file: cleaned_cosTailB.m\n",
      "Upserted 1 chunks for file: cleaned_wingMotionB.m\n",
      "Upserted 1 chunks for file: cleaned_yRotate.m\n",
      "Upserted 1 chunks for file: cleaned_L2R.m\n",
      "Upserted 1 chunks for file: cleaned_DtableG.m\n",
      "Upserted 1 chunks for file: cleaned_wingMotion.m\n",
      "Upserted 1 chunks for file: cleaned_igconvect.m\n",
      "Upserted 1 chunks for file: cleaned_SOLVER.m\n",
      "Upserted 1 chunks for file: cleaned_igcMESH.m\n",
      "Upserted 1 chunks for file: cleaned_VORTEXm.m\n",
      "Upserted 2 chunks for file: cleaned_MotionPath.m\n",
      "Upserted 1 chunks for file: cleaned_cosTailB_2.m\n",
      "Upserted 1 chunks for file: cleaned_dfvelocity.m\n",
      "Upserted 1 chunks for file: cleaned_tbshedB.m\n",
      "Upserted 1 chunks for file: cleaned_tbplotWB.m\n",
      "Upserted 1 chunks for file: cleaned_sinmovie.m\n",
      "Upserted 1 chunks for file: cleaned_tableSTailB_2.m\n",
      "Upserted 1 chunks for file: cleaned_tbdivideGAM.m\n",
      "Upserted 1 chunks for file: cleaned_offset_g6.m\n",
      "Upserted 1 chunks for file: cleaned_centerSN.m\n",
      "Upserted 1 chunks for file: cleaned_BElem.m\n",
      "Upserted 1 chunks for file: cleaned_tblrL2G_2.m\n",
      "Upserted 1 chunks for file: cleaned_wingPathL.m\n",
      "Upserted 1 chunks for file: cleaned_igVELF.m\n",
      "Upserted 1 chunks for file: cleaned_igairfoilV.m\n",
      "Upserted 2 chunks for file: cleaned_tbndData.m\n",
      "Upserted 1 chunks for file: cleaned_tblrsetMatrix.m\n",
      "Upserted 1 chunks for file: cleaned_BRelemLoc.m\n",
      "Upserted 1 chunks for file: cleaned_DcTG.m\n",
      "Upserted 1 chunks for file: cleaned_iginData.m\n",
      "Upserted 1 chunks for file: cleaned_tbsolution.m\n",
      "Upserted 1 chunks for file: cleaned_cosTailG_2.m\n",
      "Upserted 1 chunks for file: cleaned_DtableSTailG_2.m\n",
      "Upserted 1 chunks for file: cleaned_DcTB.m\n",
      "Upserted 1 chunks for file: cleaned_dfndData.m\n",
      "Upserted 1 chunks for file: cleaned_tbvelBbyT.m\n",
      "Upserted 1 chunks for file: cleaned_borderSN.m\n",
      "Upserted 1 chunks for file: cleaned_CElem.m\n",
      "Upserted 1 chunks for file: cleaned_velVortex.m\n",
      "Upserted 1 chunks for file: cleaned_tbassembleMatrix.m\n",
      "Upserted 1 chunks for file: cleaned_DtableB.m\n",
      "Upserted 1 chunks for file: cleaned_SaveFigInBackground.m\n",
      "Upserted 1 chunks for file: cleaned_igimpulses.m\n",
      "Upserted 1 chunks for file: cleaned_tblrL2T_2.m\n",
      "Upserted 7 chunks for file: cleaned_tombo.m\n",
      "Upserted 2 chunks for file: cleaned_g5.m\n",
      "Upserted 1 chunks for file: cleaned_dfconvect.m\n",
      "Upserted 1 chunks for file: cleaned_tableB.m\n",
      "Upserted 1 chunks for file: cleaned_uNormal.m\n",
      "Upserted 3 chunks for file: cleaned_igVortex_manual.m\n",
      "Upserted 1 chunks for file: cleaned_dfnVelocityw.m\n",
      "Upserted 1 chunks for file: cleaned_wingMotionNC.m\n",
      "Upserted 1 chunks for file: cleaned_chordPathTail.m\n",
      "Upserted 8 chunks for file: cleaned_idragonfly1.m\n",
      "Upserted 1 chunks for file: cleaned_center_g6.m\n",
      "Upserted 2 chunks for file: cleaned_igairfoilM.m\n",
      "Upserted 2 chunks for file: cleaned_g6.m\n",
      "Upserted 1 chunks for file: cleaned_tblrmassL2GT.m\n",
      "Upserted 1 chunks for file: cleaned_cosTailG.m\n",
      "Upserted 1 chunks for file: cleaned_dfVELOCITYF.m\n",
      "Upserted 8 chunks for file: cleaned_Copy_of_idragonfly.m\n",
      "Upserted 1 chunks for file: cleaned_Camber.m\n",
      "Upserted 1 chunks for file: cleaned_dfsolution.m\n",
      "Upserted 1 chunks for file: cleaned_tableUpSTailG.m\n",
      "Upserted 1 chunks for file: cleaned_tbwingPathNC.m\n",
      "Upserted 1 chunks for file: cleaned_tbconvW.m\n",
      "Upserted 1 chunks for file: cleaned_DtableUpSTailG.m\n",
      "Upserted 1 chunks for file: cleaned_dfwing2FRT.m\n",
      "Upserted 1 chunks for file: cleaned_cosUpTailG.m\n",
      "Upserted 1 chunks for file: cleaned_Wing.m\n",
      "Upserted 1 chunks for file: cleaned_DtableSTailG.m\n",
      "Upserted 1 chunks for file: cleaned_plot2Elm.m\n",
      "Upserted 1 chunks for file: cleaned_igplotVelocity.m\n",
      "Upserted 1 chunks for file: cleaned_tbcrossvelBbyT.m\n",
      "Upserted 2 chunks for file: cleaned_tbforceMoment.m\n",
      "Upserted 1 chunks for file: cleaned_dpDtableB.m\n",
      "Upserted 1 chunks for file: cleaned_DtableSTailB_2.m\n",
      "Upserted 1 chunks for file: cleaned_aimpulse.m\n",
      "Upserted 1 chunks for file: cleaned_selfMatrixCoef.m\n",
      "Upserted 1 chunks for file: cleaned_BRelem.m\n",
      "Upserted 1 chunks for file: cleaned_DtTG.m\n",
      "Upserted 0 chunks for file: cleaned_tomboTester.m\n",
      "Upserted 1 chunks for file: cleaned_sinusoidal.m\n",
      "Upserted 1 chunks for file: cleaned_tableUpSTailG_2.m\n",
      "Upserted 2 chunks for file: cleaned_g5Mesh.m\n",
      "Upserted 1 chunks for file: cleaned_BElem_g6.m\n",
      "Upserted 2 chunks for file: cleaned_tbvelWbyT.m\n",
      "Upserted 1 chunks for file: cleaned_WingBorder.m\n",
      "Upserted 1 chunks for file: cleaned_CRnodes.m\n",
      "Upserted 1 chunks for file: cleaned_igmatrixCoef.m\n",
      "Upserted 1 chunks for file: cleaned_tTG.m\n",
      "Upserted 1 chunks for file: cleaned_dfplotVelocity.m\n",
      "Upserted 1 chunks for file: cleaned_tbcrossMatrix.m\n",
      "Upserted 1 chunks for file: cleaned_tbwingPathTail.m\n",
      "Upserted 1 chunks for file: cleaned_DcosTailB_2.m\n",
      "Upserted 1 chunks for file: cleaned_tbwingPathNCL.m\n",
      "Upserted 1 chunks for file: cleaned_dpsimpulseWT.m\n",
      "Upserted 1 chunks for file: cleaned_tbwingM.m\n",
      "Upserted 1 chunks for file: cleaned_tableUpSTailB_2.m\n",
      "Upserted 1 chunks for file: cleaned_center.m\n",
      "Upserted 1 chunks for file: cleaned_Triangle.m\n",
      "Upserted 1 chunks for file: cleaned_saimpulse_tr.m\n",
      "Upserted 1 chunks for file: cleaned_wingPath.m\n",
      "Upserted 1 chunks for file: cleaned_tblrL2G_1.m\n",
      "Upserted 2 chunks for file: cleaned_dfwing2global.m\n",
      "Upserted 1 chunks for file: cleaned_dptableB.m\n",
      "Upserted 1 chunks for file: cleaned_plot3Elem.m\n",
      "Upserted 1 chunks for file: cleaned_dfmeshR.m\n",
      "Upserted 1 chunks for file: cleaned_DtableUpSTailG_2.m\n",
      "Upserted 1 chunks for file: cleaned_tbaddWake.m\n",
      "Upserted 1 chunks for file: cleaned_cTB.m\n",
      "Upserted 1 chunks for file: cleaned_tableSTailG_2.m\n",
      "Upserted 1 chunks for file: cleaned_tbvelWbyW.m\n",
      "Upserted 1 chunks for file: cleaned_PitchPlot.m\n",
      "Upserted 1 chunks for file: cleaned_cTG.m\n",
      "Upserted 1 chunks for file: cleaned_DECOMP.m\n",
      "Upserted 8 chunks for file: cleaned_idragonfly.m\n",
      "Upserted 1 chunks for file: cleaned_borderSN_g6.m\n",
      "Upserted 2 chunks for file: cleaned_tbnvelTbyW.m\n",
      "Upserted 2 chunks for file: cleaned_g6Mesh.m\n",
      "Upserted 1 chunks for file: cleaned_tbtranslate.m\n",
      "Upserted 1 chunks for file: cleaned_plot2Elm_g6.m\n",
      "Upserted 1 chunks for file: cleaned_BStrip.m\n",
      "Upserted 1 chunks for file: cleaned_dfimpulses.m\n",
      "Upserted 1 chunks for file: cleaned_igplotMVortexw.m\n",
      "Upserted 1 chunks for file: cleaned_centerSN_g6.m\n",
      "Upserted 1 chunks for file: cleaned_tableSTailG.m\n",
      "Upserted 1 chunks for file: cleaned_tblrswingNVs.m\n",
      "Upserted 1 chunks for file: cleaned_DcosUpTailG_2.m\n",
      "Upserted 1 chunks for file: cleaned_tbvelBbyTMatrix.m\n",
      "Upserted 1 chunks for file: cleaned_DcosUpTailB.m\n",
      "Upserted 1 chunks for file: cleaned_DcosTailB.m\n",
      "Upserted 2 chunks for file: cleaned_s5.m\n",
      "Upserted 1 chunks for file: cleaned_dfchordPath.m\n",
      "Upserted 1 chunks for file: cleaned_DtableSTailB.m\n",
      "Upserted 1 chunks for file: cleaned_tbplotGAM.m\n",
      "Upserted 1 chunks for file: cleaned_plot2Elem.m\n",
      "Upserted 1 chunks for file: cleaned_limpulsew.m\n",
      "Upserted 1 chunks for file: cleaned_DcosTailG.m\n",
      "Upserted 1 chunks for file: cleaned_dfplotMVortexw.m\n",
      "Upserted 1 chunks for file: cleaned_WingTotal.m\n",
      "Upserted 1 chunks for file: cleaned_cosUpTailB.m\n",
      "Upserted 1 chunks for file: cleaned_dpDtableG.m\n",
      "Upserted 1 chunks for file: cleaned_dptableG.m\n",
      "Upserted 1 chunks for file: cleaned_offset.m\n",
      "Upserted 1 chunks for file: cleaned_tbsimpulseWT.m\n",
      "Upserted 2 chunks for file: cleaned_mVORTEX.m\n",
      "Upserted 1 chunks for file: cleaned_WingCenter.m\n",
      "Upserted 1 chunks for file: cleaned_tTB.m\n",
      "Upserted 1 chunks for file: cleaned_dfinData.m\n",
      "Upserted 1 chunks for file: cleaned_tbassemblevelBbyT.m\n",
      "Upserted 1 chunks for file: cleaned_tableSTailB.m\n",
      "Upserted 1 chunks for file: cleaned_igvelocity.m\n",
      "Upserted 1 chunks for file: cleaned_Camber2.m\n",
      "All chunks upserted successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Pinecone API Key and Index Name\n",
    "PINECONE_API_KEY = os.environ.get("PINECONE_API_KEY")",
    "INDEX_NAME       = \"chatbot-index\"\n",
    "\n",
    "#Initialize Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Create the index if non-existent\n",
    "if INDEX_NAME not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    print(f\"Index '{INDEX_NAME}' created!\")\n",
    "else:\n",
    "    print(f\"Index '{INDEX_NAME}' already exists.\")\n",
    "\n",
    "# Describe the index to get the host\n",
    "desc = pc.describe_index(INDEX_NAME)\n",
    "host = desc.host\n",
    "\n",
    "#create a data-plane Index object\n",
    "index = Index(api_key=PINECONE_API_KEY, host=host)\n",
    "\n",
    "#Initialize the embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# helper to chunk text\n",
    "def chunk_text(text, chunk_size=1500, overlap=300):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start += (chunk_size - overlap)\n",
    "    return chunks\n",
    "\n",
    "#Upsert function\n",
    "def upsert_folder(folder_path, file_extension, chunk_size=2000, overlap=200):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(file_extension):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            text_chunks = chunk_text(content, chunk_size, overlap)\n",
    "            \n",
    "         \n",
    "            for i, chunk in enumerate(text_chunks):\n",
    "                chunk_id = f\"{file_name}_chunk_{i}\"\n",
    "                vector = model.encode(chunk).tolist()\n",
    "                metadata = {\n",
    "                    \"text\": chunk,\n",
    "                    \"original_file\": file_name,\n",
    "                    \"chunk_index\": i\n",
    "                }\n",
    "                index.upsert([(chunk_id, vector, metadata)])\n",
    "            \n",
    "            print(f\"Upserted {len(text_chunks)} chunks for file: {file_name}\")\n",
    "\n",
    "# Actually upsert .txt and .m files\n",
    "TXT_CLEANED_DIR = \"./files/processed_txt_files\"\n",
    "M_CLEANED_DIR   = \"./files/processed_m_files\"\n",
    "\n",
    "upsert_folder(TXT_CLEANED_DIR, \".txt\")\n",
    "upsert_folder(M_CLEANED_DIR,   \".m\")\n",
    "\n",
    "print(\"All chunks upserted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "878705ac-45ff-47a0-bb3a-6c316b46514a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Explain how wing rotation works for insect flight\n",
      "\n",
      "ID: Dickinson, Lehman, Sane, 1999, Wing Rotation and the Aerodynamic Basis of Insect Flight, science.284.5422.1954.txt_chunk_0\n",
      "Score: 0.76667285\n",
      "Snippet: research articles wing rotation and the aerodynamic basis of insect flight michael h dickinson1 fritzolaf lehmann2 sanjay p sane1 insects were the first animals to evolve active flight and remain unsu...\n",
      "\n",
      "ID: Dickinson, Lehman, Sane, 1999, Wing Rotation and the Aerodynamic Basis of Insect Flight, science.284.5422.1954.txt\n",
      "Score: 0.766045153\n",
      "No metadata.\n",
      "\n",
      "ID: Dickinson, Lehman, Sane, 1999, Wing Rotation and the Aerodynamic Basis of Insect Flight, science.284.5422.1954.txt_chunk_22\n",
      "Score: 0.764329553\n",
      "Snippet: flapping wings suggest that the aerodynamics of insect flight may be explained by the interaction of three distinct yet interactive mechanisms delayed stall rotational circulation and wake capture whe...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_query = \"Explain how wing rotation works for insect flight\"\n",
    "query_vector = model.encode(test_query).tolist()\n",
    "\n",
    "results = index.query(vector=query_vector, top_k=3, include_metadata=True)\n",
    "\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "for match in results[\"matches\"]:\n",
    "    print(f\"ID: {match['id']}\")\n",
    "    print(f\"Score: {match['score']}\")\n",
    "    if \"metadata\" in match:\n",
    "        snippet = match[\"metadata\"].get(\"text\", \"\")\n",
    "        print(f\"Snippet: {snippet[:200]}...\\n\")\n",
    "    else:\n",
    "        print(\"No metadata.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe0e66-c213-40c1-b4f9-4fe9095298bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot ready! Type 'exit' or 'quit' to stop.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is wake\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Based on the provided data, \"wake\" refers to the wake elements in a computational model related to the aerodynamics of wings. The wake elements contribute to the aerodynamic forces acting on the wings. The wake capture mechanism involves interactions with the wake generated from the previous wing stroke to enhance aerodynamic forces. The wake elements are convected using specific equations to model their behavior over time.\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  wwhat is flapping ffrequiency\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Flapping frequency refers to the frequency at which wings beat during flight. Some insects, like mosquitoes, have a high wing beat frequency of up to 800 Hz due to their unique wing kinematics involving relatively smaller amplitudes. This information was found in chunk \"De Manabendra, 2024, Bio-inspired Flapping Wing Aerodynamics A Review.txt_chunk_14.\"\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "#convo history\n",
    "conversation_history = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are an expert assistant. You will be provided with labeled context chunks in some system messages. \"\n",
    "            \"Use ONLY those labeled chunks to answer user queries. If partial coverage is found, please state which chunks \"\n",
    "            \"provided partial information. If the context does not answer the user, respond with 'I don't know based on the research data provided.'\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "def chatbot():\n",
    "    print(\"Chatbot ready! Type 'exit' or 'quit' to stop.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # 1. Add user message to conversation history\n",
    "        conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        #2. Embed the user's question (for retrieval)\n",
    "        query_vector = model.encode(user_input).tolist()\n",
    "\n",
    "        #3. Query Pinecone for top_k chunks\n",
    "        results = index.query(\n",
    "            vector=query_vector,\n",
    "            top_k=5, \n",
    "            include_metadata=True\n",
    "        )\n",
    "\n",
    "        #4. Build a labeled context block\n",
    "        context_parts = []\n",
    "        for match in results[\"matches\"]:\n",
    "            chunk_id = match[\"id\"]  \n",
    "            snippet_text = match[\"metadata\"].get(\"text\", \"\") if \"metadata\" in match else \"\"\n",
    "            context_parts.append(f\"[{chunk_id}]: {snippet_text}\")\n",
    "\n",
    "        context_text = \"\\n\\n\".join(context_parts)\n",
    "\n",
    "        # 5. Copy conversation history\n",
    "        conversation_plus_context = conversation_history.copy()\n",
    "\n",
    "        conversation_plus_context.append({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                f\"Here are the labeled context chunks from Pinecone:\\n\\n\"\n",
    "                f\"{context_text}\\n\\n\"\n",
    "                f\"Remember to cite chunk IDs if you use them. \"\n",
    "                f\"If partial coverage is found, say so and mention which chunk IDs. \"\n",
    "                f\"If none is relevant, respond with 'I don't know based on the research data provided.'\"\n",
    "            )\n",
    "        })\n",
    "\n",
    "        #6.Call OpenAI with the entire conversation\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=conversation_plus_context,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            answer = response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            answer = f\"Error calling OpenAI API: {e}\"\n",
    "\n",
    "        #7. Add assistant's answer to conversation history\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "\n",
    "        print(f\"Chatbot: {answer}\\n{'-'*60}\\n\")\n",
    "        \n",
    "chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f335ffa0-04aa-4d8c-979a-06ca5f8bb1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
